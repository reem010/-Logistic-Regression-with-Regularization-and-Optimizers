{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc4d15",
   "metadata": {
    "id": "4cdc4d15"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b78cc9",
   "metadata": {
    "id": "d2b78cc9"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train=np.array( x_train,dtype = float)\n",
    "y_train=np.array( y_train,dtype = float)\n",
    "x_test=np.array( x_test,dtype = float)\n",
    "y_test=np.array( y_test,dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4293f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe4293f2",
    "outputId": "d9636ab6-cff5-48b2-af4d-ce55e405d76a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c0ff9",
   "metadata": {
    "id": "6b3c0ff9"
   },
   "outputs": [],
   "source": [
    "# Select only the images and labels corresponding to digit 0 and 1\n",
    "mask = np.logical_or(y_train == 0, y_train == 1)\n",
    "x_train = x_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "mask = np.logical_or(y_test == 0, y_test == 1)\n",
    "x_test = x_test[mask]\n",
    "y_test = y_test[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b600272",
   "metadata": {
    "id": "7b600272"
   },
   "outputs": [],
   "source": [
    "#standrize\n",
    "x_train= (x_train - np.mean(x_train))/ np.std(x_train)\n",
    "x_test= (x_test - np.mean(x_test))/ np.std(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b16dcb",
   "metadata": {
    "id": "49b16dcb"
   },
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(x_train.shape[0],-1)\n",
    "x_test=x_test.reshape(x_test.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OJtESuv_AGb3",
   "metadata": {
    "id": "OJtESuv_AGb3"
   },
   "outputs": [],
   "source": [
    "# Shuffle images and labels together\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
    "x_test, y_test = shuffle(x_test, y_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c70ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b2c70ea",
    "outputId": "bd80e541-bbd3-4930-99a4-dc4bf3b90f71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12665,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ae712",
   "metadata": {
    "id": "ca7ae712"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1/(1+np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636KV3YhAuIS",
   "metadata": {
    "id": "636KV3YhAuIS"
   },
   "outputs": [],
   "source": [
    "def Logistic_regression(x , y , eta  ,iterations, batch_size ):\n",
    "    \n",
    "    np.random.seed(35)\n",
    "    w = np.random.rand(x.shape[1],1)\n",
    "    b = np.random.rand(1)\n",
    "    num_samples = len(y)\n",
    "    error = []\n",
    "    tol = 0.0000001\n",
    "    num_batches = num_samples // batch_size\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        for batch in range(num_batches):\n",
    "            start= batch * batch_size\n",
    "            end = start + batch_size\n",
    "            x_mini = x[start:end]\n",
    "            y_mini = y[start:end]\n",
    "            \n",
    "            z = np.dot(x_mini,w)+b\n",
    "            phiz = sigmoid(z)\n",
    "            phiz = phiz.T\n",
    "            error.append(np.mean(((-y_mini*np.log(phiz+tol))-(((1-y_mini)*(np.log((1-phiz)+tol)))))))\n",
    "            w = w - eta *((np.dot(phiz - y_mini, x_mini ))/ num_samples).T\n",
    "            b = b - eta * np.mean(phiz - y_mini)\n",
    "\n",
    "            if error[i] <= tol:\n",
    "                  break \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df9776",
   "metadata": {
    "id": "95df9776"
   },
   "outputs": [],
   "source": [
    "def Logistic_regression_L1(x , y , eta  ,iterations, lamda , batch_size=x_train.shape[0] ):\n",
    "    \n",
    "    np.random.seed(35)\n",
    "    w = np.random.rand(x.shape[1],1)\n",
    "    b = np.random.rand(1)\n",
    "    num_samples = len(y)\n",
    "    error = []\n",
    "    tol = 0.0000001\n",
    "    num_batches = num_samples // batch_size\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        for batch in range(num_batches):\n",
    "            start= batch * batch_size\n",
    "            end = start + batch_size\n",
    "            x_mini = x[start:end]\n",
    "            y_mini = y[start:end]\n",
    "            \n",
    "            z = np.dot(x_mini,w)+b\n",
    "            phiz = sigmoid(z)\n",
    "            phiz = phiz.T\n",
    "            l1= (lamda/(2*len(y_mini))) * np.abs(w)\n",
    "            error.append(np.mean(((-y_mini*np.log(phiz+tol))-(((1-y_mini)*(np.log((1-phiz)+tol)))))+np.sum(l1)))\n",
    "            w = w - eta *((np.dot(phiz - y_mini, x_mini ) + (lamda/(2)) )/ num_samples).T\n",
    "            b = b - eta * np.mean(phiz - y_mini)\n",
    "\n",
    "            if error[i] <= tol:\n",
    "                  break \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72489f8",
   "metadata": {
    "id": "b72489f8"
   },
   "outputs": [],
   "source": [
    "def Logistic_regression_RMS(x , y , eta , iterations , B = 0.9):\n",
    "    \n",
    "    np.random.seed(35)\n",
    "    w = np.random.rand(x.shape[1],1)\n",
    "    b = np.random.rand(1)\n",
    "    num_samples = len(y)\n",
    "    error = []\n",
    "    tol = 0.0000001\n",
    "    RMS_vdw = 0\n",
    "    RMS_vdb = 0\n",
    "    t=0\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z = np.dot(x,w)+b\n",
    "        phiz = sigmoid(z)\n",
    "        phiz = phiz.T\n",
    "        error.append(np.mean(((-y*np.log(phiz+tol))-(((1-y)*(np.log((1-phiz)+tol)))))))\n",
    "        dw = ((np.dot(phiz - y, x ))/ num_samples).T\n",
    "        db= np.mean(phiz - y)\n",
    "        t+=1\n",
    "        RMS_vdw = (B * RMS_vdw + (1-B) * np.square(dw) )/(1-B**t)\n",
    "        RMS_vdb = (B * RMS_vdb+ (1-B) * np.square(db) )/(1-B**t)\n",
    "        w = w - eta * (B/np.sqrt(RMS_vdw+tol))*dw\n",
    "        b = b - eta * (B/np.sqrt(RMS_vdb+tol))*db\n",
    "        \n",
    "        if error[i] <= tol:\n",
    "            break \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fu5gfbLu6pxd",
   "metadata": {
    "id": "fu5gfbLu6pxd"
   },
   "outputs": [],
   "source": [
    "def Logistic_regression_ADAM(x , y , eta , iterations , B = 0.9):\n",
    "    \n",
    "    np.random.seed(35)\n",
    "    w = np.random.rand(x.shape[1],1)\n",
    "    b = np.random.rand(1)\n",
    "    num_samples = len(y)\n",
    "    error = []\n",
    "    tol = 0.0000001\n",
    "    RMS_vdw = 0\n",
    "    momentum_vdw = 0\n",
    "    momentum_vdb = 0\n",
    "    RMS_vdb = 0\n",
    "    t=0\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z = np.dot(x,w) + b\n",
    "        phiz = sigmoid(z)\n",
    "        phiz = phiz.T\n",
    "        error.append(np.mean(((-y*np.log(phiz+tol))-(((1-y)*(np.log((1-phiz)+tol)))))))\n",
    "        dw = ((np.dot(phiz - y, x ))/ num_samples).T\n",
    "        db= np.mean(phiz - y)\n",
    "        t+=1\n",
    "        RMS_vdw = (B * RMS_vdw + (1-B) * np.square(dw) )/(1-B**t)\n",
    "        momentum_vdw = (B * momentum_vdw + (1-B) * dw )/(1-B**t)\n",
    "        RMS_vdb = (B * RMS_vdb+ (1-B) * np.square(db) )/(1-B**t)\n",
    "        momentum_vdb = (B * momentum_vdb + (1-B) * db )/(1-B**t)\n",
    "        w = w - eta * (momentum_vdw/np.sqrt(RMS_vdw+tol))\n",
    "        b = b - eta * (momentum_vdb/np.sqrt(RMS_vdb+tol))\n",
    "        \n",
    "        if error[i] <= tol:\n",
    "            break \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7864084",
   "metadata": {
    "id": "e7864084"
   },
   "outputs": [],
   "source": [
    "def test(w,b):\n",
    "    z = np.dot(x_test,w)\n",
    "    z = sigmoid(z)\n",
    "    y_pred = np.where(z>0.5 ,1,0)\n",
    "    y_pred=y_pred.reshape(-1)\n",
    "    acc = np.mean(y_pred==y_test)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uwP8yBk7CFYW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uwP8yBk7CFYW",
    "outputId": "6800bc01-f007-4686-b651-1313f9826a90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-e917b25034e6>:2: RuntimeWarning: overflow encountered in exp\n",
      "  return (1/(1+np.exp(-z)))\n"
     ]
    }
   ],
   "source": [
    "iter = 700\n",
    "w1 , b1= Logistic_regression(x_train,y_train,0.001,iter,50)\n",
    "w2 , b2= Logistic_regression(x_train,y_train,0.001,iter,1000)\n",
    "w3 , b3= Logistic_regression_L1(x_train,y_train,0.001,iter,0.001)\n",
    "w4 , b4= Logistic_regression_L1(x_train,y_train,0.001,iter,1000)\n",
    "w5 , b5= Logistic_regression_RMS(x_train,y_train,0.001,iter)\n",
    "w6 , b6= Logistic_regression_ADAM(x_train,y_train,0.001,iter)\n",
    "\n",
    "acc1 =test(w1,b1)\n",
    "acc2 =test(w2,b2)\n",
    "acc3 =test(w3,b3)\n",
    "acc4 =test(w4,b4)\n",
    "acc5 =test(w5,b5)\n",
    "acc6 =test(w6,b6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uHUicDBTGBw1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHUicDBTGBw1",
    "outputId": "fd488880-5ec9-4060-eced-8be9626ae32c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of logistic regression with batch size 50 : 0.6127659574468085\n",
      "accuracy of logistic regression with batch size 1000 : 0.6269503546099291\n",
      "we note that the bigger the batch size the bigger the accuracy because By using a \n",
      "larger batch size, the model receives more diverse samples during each update step\n",
      " \n",
      "accuracy of logistic regression with L1 regulization with L=0.001 : 0.6486997635933807\n",
      "accuracy of logistic regression with L1 regulization with L=1000 : 0.6808510638297872\n",
      "we note that the bigger the lamda the bigger the accuracy because we \n",
      "depend more on the previous dw which makes the update value more strenched\n",
      "we note that lasso is better than normal logistic because Lasso regularization\n",
      " provides a sparse solution by setting coefficients to exactly zero. \n",
      "This makes the model more interpretable,as the non-zero coefficients directly \n",
      "indicate the important features that contribute to the predictions\n",
      " \n",
      "accuracy of logisitic regression with RMS optimizer : 0.9782505910165484\n",
      "accuracy of logistic regression with ADAM optimizer : 0.9947990543735225\n",
      "we note that ADAM optimizer gives us the biggest accuracy then RMS then lasso then normal logistic regression \n",
      "Adam combines adaptive learning rates and momentum, leading to faster convergence and robust performance.\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy of logistic regression with batch size 50 : \"+ str(acc1))\n",
    "print(\"accuracy of logistic regression with batch size 1000 : \"+ str(acc2))\n",
    "print(\"we note that the bigger the batch size the bigger the accuracy because By using a \")\n",
    "print(\"larger batch size, the model receives more diverse samples during each update step\")\n",
    "print(\" \")\n",
    "print(\"accuracy of logistic regression with L1 regulization with L=0.001 : \"+ str(acc3))\n",
    "print(\"accuracy of logistic regression with L1 regulization with L=1000 : \"+ str(acc4))\n",
    "print(\"we note that the bigger the lamda the bigger the accuracy because we \")\n",
    "print(\"depend more on the previous dw which makes the update value more strenched\")\n",
    "print(\"we note that lasso is better than normal logistic because Lasso regularization\")\n",
    "print(\"provides a sparse solution by setting coefficients to exactly zero. \") \n",
    "print(\"This makes the model more interpretable,as the non-zero coefficients directly \")\n",
    "print(\"indicate the important features that contribute to the predictions\")\n",
    "print(\" \")\n",
    "print(\"accuracy of logisitic regression with RMS optimizer : \"+ str(acc5))\n",
    "print(\"accuracy of logistic regression with ADAM optimizer : \"+ str(acc6))\n",
    "print(\"we note that ADAM optimizer gives us the biggest accuracy then RMS then lasso then normal logistic regression \")\n",
    "print(\"Adam combines adaptive learning rates and momentum, leading to faster convergence and robust performance.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6oSS9L2EJR60",
   "metadata": {
    "id": "6oSS9L2EJR60"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
